{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "558ec1e6",
   "metadata": {},
   "source": [
    "# Method 6 — Intelligent (Layout-Aware) Multimodal Chunker + Summaries + Embeddings + FAISS\n",
    "\n",
    "\n",
    "This notebook demonstrates a **layout-aware / intelligent multimodal chunking** pipeline:\n",
    "\n",
    "1. **Parse with a layout-aware parser** (choose one):\n",
    "   - **Azure Document Intelligence (prebuilt-layout)** (recommended if you have Azure keys)\n",
    "   - **LandingAI ADE Parse** (if you already have the ADE JSON)\n",
    "   - **Bring-your-own JSON** in the same schema (fallback)\n",
    "2. Convert parser output into **typed elements** (`text`, `table`, `figure`) with:\n",
    "   - **page number**, **bounding box / polygon**, (optional) **confidence**\n",
    "3. **Hierarchical chunking** of text based on headings/sections when available.\n",
    "4. **Crop figures/tables from the PDF** using their bounding regions.\n",
    "5. Create **summaries**:\n",
    "   - Figures: GPT-4o vision description (or BLIP if you want offline)\n",
    "   - Tables: summarize from HTML/markdown\n",
    "6. Embed all retrieval units (text chunks + figure summaries + table summaries) and index in **FAISS/VectorDB (Azure AI Search, Pinecone, Milvus, Vespa, etc - recommended in Production)**.\n",
    "7. Inference:\n",
    "   - Retrieve text/table chunks → generate an answer **with citations** (chunk ids + pages)\n",
    "   - Use citations to **restrict figure search space** to cited pages (±1 window)\n",
    "   - Retrieve the most relevant figures within that narrowed search space\n",
    "\n",
    "> Default embeddings: **Cohere text embeddings** for all summaries/chunks. You can swap models easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38eff7d",
   "metadata": {},
   "source": [
    "## Install (run once)\n",
    "\n",
    "```bash\n",
    "pip install pymupdf pillow faiss-cpu tqdm cohere openai azure-ai-documentintelligence\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec699d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0) Config\n",
    "# =========================\n",
    "import os\n",
    "\n",
    "PDF_PATH = \"YOUR_PDF_HERE.pdf\"   # <-- set this\n",
    "ARTIFACTS_DIR = \"artifacts_layout\"\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "# Choose parser: \"azure_di\" | \"landingai_json\" | \"json_file\"\n",
    "PARSER_MODE = \"json_file\"\n",
    "\n",
    "# --- If PARSER_MODE == \"azure_di\" ---\n",
    "AZURE_DI_ENDPOINT = os.environ.get(\"AZURE_DI_ENDPOINT\", \"\")\n",
    "AZURE_DI_KEY = os.environ.get(\"AZURE_DI_KEY\", \"\")\n",
    "AZURE_DI_MODEL_ID = \"prebuilt-layout\"\n",
    "\n",
    "# --- If PARSER_MODE == \"landingai_json\" or \"json_file\" ---\n",
    "PARSE_JSON_PATH = \"YOUR_PARSE_OUTPUT.json\"  # ADE parse JSON or your own JSON in expected schema\n",
    "\n",
    "# Summaries / answers (requires OpenAI)\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "OPENAI_VISION_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_TEXT_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "# Embeddings (requires Cohere)\n",
    "COHERE_API_KEY = os.environ.get(\"COHERE_API_KEY\", \"\")\n",
    "COHERE_TEXT_MODEL = \"embed-multilingual-v3.0\"\n",
    "\n",
    "# Retrieval parameters\n",
    "TOP_K_TEXT = 12\n",
    "TOP_K_ASSETS = 6\n",
    "PAGE_WINDOW = 1  # cited pages ± this window for figures/tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Schemas + helpers\n",
    "# =========================\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import re, json, base64\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class Element:\n",
    "    element_id: str\n",
    "    element_type: str  # \"text\" | \"table\" | \"figure\"\n",
    "    page: int          # 1-based\n",
    "    content: str       # markdown/text for text, html/markdown for table, \"\" for figure\n",
    "    bbox: Optional[Dict[str, float]] = None     # normalized {left, top, right, bottom} in [0,1] if available\n",
    "    polygon: Optional[List[float]] = None       # Azure polygon (x1,y1,x2,y2,...)\n",
    "    confidence: Optional[float] = None\n",
    "    heading_path: Optional[List[str]] = None\n",
    "\n",
    "@dataclass\n",
    "class RetrievalUnit:\n",
    "    unit_id: str\n",
    "    unit_type: str     # \"text\" | \"table\" | \"figure\"\n",
    "    page: int\n",
    "    text_for_embedding: str\n",
    "    raw_content_ref: Optional[str] = None\n",
    "    meta: Optional[Dict[str, Any]] = None\n",
    "\n",
    "def clean_anchor_tags(s: str) -> str:\n",
    "    return re.sub(r\"<a id=['\\\"][a-f0-9\\-]+['\\\"]></a>\\s*\", \"\", s).strip()\n",
    "\n",
    "def ensure_dir(p: str):\n",
    "    import os\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30693873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Parse document with a layout-aware parser\n",
    "# =========================\n",
    "from typing import List\n",
    "import os, json\n",
    "\n",
    "def parse_from_json(parse_json: Dict[str, Any]) -> List[Element]:\n",
    "    # Supports LandingAI ADE-like schema: parse_json['chunks'] with type/id/markdown/text/grounding.\n",
    "    chunks = parse_json.get(\"chunks\", [])\n",
    "    elements: List[Element] = []\n",
    "\n",
    "    for ch in chunks:\n",
    "        t = ch.get(\"type\", \"text\")\n",
    "        if t not in (\"text\", \"table\", \"figure\"):\n",
    "            t = \"text\"\n",
    "\n",
    "        cid = ch.get(\"id\") or ch.get(\"chunk_id\") or f\"chunk_{len(elements)+1}\"\n",
    "        grounding = ch.get(\"grounding\", {}) or {}\n",
    "        page = grounding.get(\"page\")\n",
    "        if page is None:\n",
    "            page = ch.get(\"page\") or 1\n",
    "        page = int(page)\n",
    "\n",
    "        box = grounding.get(\"box\") or grounding.get(\"bbox\") or None\n",
    "        conf = grounding.get(\"confidence\") or ch.get(\"confidence\")\n",
    "\n",
    "        content = ch.get(\"markdown\") or ch.get(\"text\") or \"\"\n",
    "        content = clean_anchor_tags(content)\n",
    "\n",
    "        elements.append(Element(\n",
    "            element_id=str(cid),\n",
    "            element_type=t,\n",
    "            page=page,\n",
    "            content=content,\n",
    "            bbox=box,\n",
    "            confidence=conf\n",
    "        ))\n",
    "    return elements\n",
    "\n",
    "def parse_with_azure_document_intelligence(pdf_path: str) -> List[Element]:\n",
    "    # Calls Azure DI Layout model and converts output into Elements.\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "    from azure.ai.documentintelligence.models import ContentFormat\n",
    "\n",
    "    if not AZURE_DI_ENDPOINT or not AZURE_DI_KEY:\n",
    "        raise ValueError(\"Set AZURE_DI_ENDPOINT and AZURE_DI_KEY env vars.\")\n",
    "\n",
    "    client = DocumentIntelligenceClient(endpoint=AZURE_DI_ENDPOINT, credential=AzureKeyCredential(AZURE_DI_KEY))\n",
    "\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        poller = client.begin_analyze_document(\n",
    "            model_id=AZURE_DI_MODEL_ID,\n",
    "            analyze_request=f,\n",
    "            output_content_format=ContentFormat.MARKDOWN,\n",
    "        )\n",
    "    result = poller.result()\n",
    "\n",
    "    elements: List[Element] = []\n",
    "\n",
    "    if getattr(result, \"paragraphs\", None):\n",
    "        for i, p in enumerate(result.paragraphs):\n",
    "            page = 1\n",
    "            poly = None\n",
    "            if p.bounding_regions:\n",
    "                page = p.bounding_regions[0].page_number\n",
    "                poly = p.bounding_regions[0].polygon\n",
    "            elements.append(Element(\n",
    "                element_id=f\"az_para_{i}\",\n",
    "                element_type=\"text\",\n",
    "                page=int(page),\n",
    "                content=(p.content or \"\").strip(),\n",
    "                polygon=list(poly) if poly else None,\n",
    "                confidence=getattr(p, \"confidence\", None)\n",
    "            ))\n",
    "\n",
    "    if getattr(result, \"tables\", None):\n",
    "        for i, t in enumerate(result.tables):\n",
    "            page = 1\n",
    "            poly = None\n",
    "            if t.bounding_regions:\n",
    "                page = t.bounding_regions[0].page_number\n",
    "                poly = t.bounding_regions[0].polygon\n",
    "\n",
    "            max_row = max([c.row_index for c in t.cells], default=-1)\n",
    "            max_col = max([c.column_index for c in t.cells], default=-1)\n",
    "            grid = [[\"\" for _ in range(max_col+1)] for _ in range(max_row+1)]\n",
    "            for c in t.cells:\n",
    "                grid[c.row_index][c.column_index] = (c.content or \"\").strip()\n",
    "\n",
    "            html = \"<table>\" + \"\".join(\n",
    "                \"<tr>\" + \"\".join(f\"<td>{cell}</td>\" for cell in row) + \"</tr>\"\n",
    "                for row in grid\n",
    "            ) + \"</table>\"\n",
    "\n",
    "            elements.append(Element(\n",
    "                element_id=f\"az_table_{i}\",\n",
    "                element_type=\"table\",\n",
    "                page=int(page),\n",
    "                content=html,\n",
    "                polygon=list(poly) if poly else None\n",
    "            ))\n",
    "\n",
    "    return elements\n",
    "\n",
    "if PARSER_MODE == \"azure_di\":\n",
    "    elements = parse_with_azure_document_intelligence(PDF_PATH)\n",
    "elif PARSER_MODE in (\"landingai_json\", \"json_file\"):\n",
    "    with open(PARSE_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        parse_json = json.load(f)\n",
    "    elements = parse_from_json(parse_json)\n",
    "else:\n",
    "    raise ValueError(\"Unknown PARSER_MODE\")\n",
    "\n",
    "print(\"Parsed elements:\", len(elements))\n",
    "print(\"Types:\", {e.element_type for e in elements})\n",
    "print(\"Example:\", elements[0] if elements else None)\n",
    "\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"elements_raw.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump([asdict(e) for e in elements], f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36759bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3) Build hierarchy + intelligent chunking\n",
    "# =========================\n",
    "def guess_is_heading(text: str) -> bool:\n",
    "    t = text.strip()\n",
    "    if len(t) < 3:\n",
    "        return False\n",
    "    if re.match(r\"^(\\d+(\\.\\d+)*)\\s+\\S+\", t):\n",
    "        return True\n",
    "    if t.isupper() and len(t) <= 80:\n",
    "        return True\n",
    "    if re.match(r\"^(chapter|section)\\b\", t.lower()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def assign_heading_paths(elements: List[Element]) -> List[Element]:\n",
    "    els = sorted(elements, key=lambda e: (e.page, e.element_id))\n",
    "    current_path: List[str] = []\n",
    "    for e in els:\n",
    "        if e.element_type != \"text\":\n",
    "            continue\n",
    "        if guess_is_heading(e.content):\n",
    "            current_path = [e.content.strip()]\n",
    "            e.heading_path = current_path.copy()\n",
    "        else:\n",
    "            e.heading_path = current_path.copy() if current_path else []\n",
    "    return els\n",
    "\n",
    "def section_chunk_text(elements: List[Element], max_chars: int = 1400, overlap: int = 200) -> List[RetrievalUnit]:\n",
    "    units: List[RetrievalUnit] = []\n",
    "    buf = \"\"\n",
    "    buf_meta = None\n",
    "\n",
    "    def flush():\n",
    "        nonlocal buf, buf_meta\n",
    "        if buf_meta and buf.strip():\n",
    "            same_prefix = [u for u in units if u.meta and u.meta.get(\"prefix\")==buf_meta[\"prefix\"]]\n",
    "            uid = f\"{buf_meta['prefix']}_{len(same_prefix)+1}\"\n",
    "            units.append(RetrievalUnit(\n",
    "                unit_id=uid,\n",
    "                unit_type=\"text\",\n",
    "                page=buf_meta[\"page\"],\n",
    "                text_for_embedding=buf.strip(),\n",
    "                meta=buf_meta\n",
    "            ))\n",
    "        buf = \"\"\n",
    "        buf_meta = None\n",
    "\n",
    "    for e in elements:\n",
    "        if e.element_type != \"text\":\n",
    "            continue\n",
    "        heading = \" > \".join(e.heading_path or []) if e.heading_path else \"\"\n",
    "        prefix = f\"p{e.page}_sec{abs(hash(heading))%10_000}\"\n",
    "\n",
    "        if buf_meta is None:\n",
    "            buf_meta = {\"page\": e.page, \"heading\": heading, \"prefix\": prefix}\n",
    "\n",
    "        if (buf_meta[\"page\"] != e.page) or (buf_meta[\"heading\"] != heading):\n",
    "            flush()\n",
    "            buf_meta = {\"page\": e.page, \"heading\": heading, \"prefix\": prefix}\n",
    "\n",
    "        piece = e.content.strip()\n",
    "        if not piece:\n",
    "            continue\n",
    "\n",
    "        if len(buf) + len(piece) + 1 > max_chars:\n",
    "            flush()\n",
    "            buf = piece[-overlap:] if overlap and len(piece) > overlap else piece\n",
    "            buf_meta = {\"page\": e.page, \"heading\": heading, \"prefix\": prefix}\n",
    "        else:\n",
    "            buf = (buf + \"\\n\" + piece).strip() if buf else piece\n",
    "\n",
    "    flush()\n",
    "    return units\n",
    "\n",
    "elements_sorted = assign_heading_paths(elements)\n",
    "text_units = section_chunk_text(elements_sorted)\n",
    "\n",
    "print(\"Text retrieval units:\", len(text_units))\n",
    "print(\"Example text unit:\", text_units[0] if text_units else None)\n",
    "\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"text_units.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump([asdict(u) for u in text_units], f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01923452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) Crop figures and tables from PDF using bounding boxes\n",
    "# =========================\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "fig_dir = ensure_dir(os.path.join(ARTIFACTS_DIR, \"figures\"))\n",
    "tbl_dir = ensure_dir(os.path.join(ARTIFACTS_DIR, \"tables\"))\n",
    "\n",
    "doc = fitz.open(PDF_PATH)\n",
    "\n",
    "def rect_from_bbox(page, bbox: Dict[str, float]) -> fitz.Rect:\n",
    "    return fitz.Rect(\n",
    "        bbox[\"left\"] * page.rect.width,\n",
    "        bbox[\"top\"] * page.rect.height,\n",
    "        bbox[\"right\"] * page.rect.width,\n",
    "        bbox[\"bottom\"] * page.rect.height\n",
    "    )\n",
    "\n",
    "def rect_from_polygon(page, polygon: List[float], unit_hint: str = \"points\") -> fitz.Rect:\n",
    "    xs = polygon[0::2]\n",
    "    ys = polygon[1::2]\n",
    "    x0, x1 = min(xs), max(xs)\n",
    "    y0, y1 = min(ys), max(ys)\n",
    "    if unit_hint == \"inch\":\n",
    "        x0, x1, y0, y1 = x0*72.0, x1*72.0, y0*72.0, y1*72.0\n",
    "    return fitz.Rect(x0, y0, x1, y1)\n",
    "\n",
    "asset_units: List[RetrievalUnit] = []\n",
    "\n",
    "for e in elements_sorted:\n",
    "    if e.element_type not in (\"figure\", \"table\"):\n",
    "        continue\n",
    "    if e.page < 1 or e.page > len(doc):\n",
    "        continue\n",
    "    page = doc.load_page(e.page - 1)\n",
    "\n",
    "    rect = None\n",
    "    if e.bbox:\n",
    "        rect = rect_from_bbox(page, e.bbox)\n",
    "    elif e.polygon:\n",
    "        rect = rect_from_polygon(page, e.polygon, unit_hint=\"points\")\n",
    "\n",
    "    if rect is None:\n",
    "        continue\n",
    "\n",
    "    pix = page.get_pixmap(clip=rect, dpi=200)\n",
    "    img_bytes = pix.tobytes(\"png\")\n",
    "\n",
    "    if e.element_type == \"figure\":\n",
    "        out_path = os.path.join(fig_dir, f\"{e.element_id}.png\")\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(img_bytes)\n",
    "        asset_units.append(RetrievalUnit(\n",
    "            unit_id=f\"fig_{e.element_id}\",\n",
    "            unit_type=\"figure\",\n",
    "            page=e.page,\n",
    "            text_for_embedding=\"\",\n",
    "            raw_content_ref=out_path,\n",
    "            meta={\"source_element_id\": e.element_id}\n",
    "        ))\n",
    "    else:\n",
    "        out_path = os.path.join(tbl_dir, f\"{e.element_id}.png\")\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(img_bytes)\n",
    "\n",
    "        html_path = os.path.join(tbl_dir, f\"{e.element_id}.html\")\n",
    "        with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(e.content or \"\")\n",
    "\n",
    "        asset_units.append(RetrievalUnit(\n",
    "            unit_id=f\"tbl_{e.element_id}\",\n",
    "            unit_type=\"table\",\n",
    "            page=e.page,\n",
    "            text_for_embedding=\"\",\n",
    "            raw_content_ref=html_path,\n",
    "            meta={\"crop_image_path\": out_path, \"source_element_id\": e.element_id}\n",
    "        ))\n",
    "\n",
    "doc.close()\n",
    "\n",
    "print(\"Asset units created (cropped):\", len(asset_units))\n",
    "print(\"Example asset:\", asset_units[0] if asset_units else None)\n",
    "\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"asset_units_raw.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump([asdict(u) for u in asset_units], f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) Summarize figures + tables (for retrieval)\n",
    "# =========================\n",
    "import os, json, base64\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def b64_image(path: str) -> str:\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def describe_figure(image_path: str) -> str:\n",
    "    b64 = b64_image(image_path)\n",
    "    resp = client.responses.create(\n",
    "        model=OPENAI_VISION_MODEL,\n",
    "        input=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": \"Describe this figure for semantic search. Include what it depicts, labels, and key entities. Keep it concise but informative.\"},\n",
    "                {\"type\": \"input_image\", \"image_url\": f\"data:image/png;base64,{b64}\"},\n",
    "            ],\n",
    "        }],\n",
    "    )\n",
    "    return resp.output_text.strip()\n",
    "\n",
    "def summarize_table_html(table_html: str) -> str:\n",
    "    resp = client.responses.create(\n",
    "        model=OPENAI_TEXT_MODEL,\n",
    "        input=f\"\"\"Summarize this table for retrieval. Mention what the table represents, key columns, and notable values or trends.\n",
    "Return a concise summary (2-6 sentences).\n",
    "\n",
    "TABLE HTML:\n",
    "{table_html}\n",
    "\"\"\"\n",
    "    )\n",
    "    return resp.output_text.strip()\n",
    "\n",
    "cache_path = os.path.join(ARTIFACTS_DIR, \"asset_summaries.json\")\n",
    "summaries = json.load(open(cache_path, \"r\", encoding=\"utf-8\")) if os.path.exists(cache_path) else {}\n",
    "\n",
    "for u in asset_units:\n",
    "    if u.unit_id in summaries:\n",
    "        continue\n",
    "    if u.unit_type == \"figure\":\n",
    "        summaries[u.unit_id] = describe_figure(u.raw_content_ref)\n",
    "    elif u.unit_type == \"table\":\n",
    "        html = open(u.raw_content_ref, \"r\", encoding=\"utf-8\").read()\n",
    "        summaries[u.unit_id] = summarize_table_html(html)\n",
    "\n",
    "with open(cache_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summaries, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "for u in asset_units:\n",
    "    u.text_for_embedding = summaries.get(u.unit_id, \"\")\n",
    "\n",
    "print(\"Example summaries:\", list(summaries.items())[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dbfc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 6) Embed retrieval units + build FAISS index\n",
    "# =========================\n",
    "import faiss\n",
    "import cohere\n",
    "\n",
    "co = cohere.ClientV2(api_key=COHERE_API_KEY)\n",
    "\n",
    "def l2_normalize(x: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    n = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    return x / np.clip(n, eps, None)\n",
    "\n",
    "def cohere_embed_texts(texts: List[str], model: str, input_type: str, batch_size: int = 64) -> np.ndarray:\n",
    "    vecs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = [{\"content\": [{\"type\": \"text\", \"text\": t}]} for t in batch]\n",
    "        resp = co.embed(model=model, inputs=inputs, input_type=input_type, embedding_types=[\"float\"])\n",
    "        vecs.append(np.array(resp.embeddings.float_, dtype=np.float32))\n",
    "    return np.vstack(vecs) if vecs else np.zeros((0, 1), dtype=np.float32)\n",
    "\n",
    "def build_faiss_ip_index(emb: np.ndarray) -> faiss.Index:\n",
    "    emb = emb.astype(np.float32)\n",
    "    idx = faiss.IndexFlatIP(emb.shape[1])\n",
    "    idx.add(emb)\n",
    "    return idx\n",
    "\n",
    "def faiss_search(index: faiss.Index, q: np.ndarray, top_k: int):\n",
    "    D, I = index.search(q.astype(np.float32), top_k)\n",
    "    return D[0], I[0]\n",
    "\n",
    "all_units: List[RetrievalUnit] = text_units + asset_units\n",
    "\n",
    "texts_to_embed = [u.text_for_embedding for u in all_units]\n",
    "emb = cohere_embed_texts(texts_to_embed, model=COHERE_TEXT_MODEL, input_type=\"search_document\")\n",
    "emb_n = l2_normalize(emb)\n",
    "\n",
    "index = build_faiss_ip_index(emb_n)\n",
    "\n",
    "faiss.write_index(index, os.path.join(ARTIFACTS_DIR, \"faiss_all_units_cohere.index\"))\n",
    "np.save(os.path.join(ARTIFACTS_DIR, \"all_units_embeddings.npy\"), emb_n)\n",
    "\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"all_units_meta.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump([asdict(u) for u in all_units], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Indexed units:\", len(all_units), \"dim:\", emb_n.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 7) Inference: answer with citations + restrict assets by cited pages\n",
    "# =========================\n",
    "import os, json, re\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "index = faiss.read_index(os.path.join(ARTIFACTS_DIR, \"faiss_all_units_cohere.index\"))\n",
    "all_units = [RetrievalUnit(**u) for u in json.load(open(os.path.join(ARTIFACTS_DIR, \"all_units_meta.json\"), \"r\", encoding=\"utf-8\"))]\n",
    "emb_n = np.load(os.path.join(ARTIFACTS_DIR, \"all_units_embeddings.npy\"))\n",
    "\n",
    "def embed_query(query: str) -> np.ndarray:\n",
    "    q = cohere_embed_texts([query], model=COHERE_TEXT_MODEL, input_type=\"search_query\")\n",
    "    return l2_normalize(q)\n",
    "\n",
    "def retrieve_units(query: str, top_k: int = 12):\n",
    "    q = embed_query(query)\n",
    "    scores, idxs = faiss_search(index, q, top_k)\n",
    "    return [(all_units[i], float(scores[j])) for j, i in enumerate(idxs)]\n",
    "\n",
    "def build_context_for_answer(hits):\n",
    "    parts = []\n",
    "    for u, _ in hits:\n",
    "        if u.unit_type in (\"text\", \"table\"):\n",
    "            parts.append(f\"[{u.unit_id} | p{u.page}] {u.text_for_embedding}\")\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "def answer_with_citations(query: str, hits) -> str:\n",
    "    ctx = build_context_for_answer(hits)\n",
    "    prompt = f\"\"\"You are answering a question using ONLY the provided context excerpts.\n",
    "- Cite sources inline using square brackets with the unit id, e.g., [p3_sec1234_2] or [tbl_az_table_1].\n",
    "- If you don't know, say so.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Context:\n",
    "{ctx}\n",
    "\"\"\"\n",
    "    resp = client.responses.create(model=OPENAI_TEXT_MODEL, input=prompt)\n",
    "    return resp.output_text.strip()\n",
    "\n",
    "def cited_pages_from_answer(answer: str) -> set:\n",
    "    pages = set(int(p) for p in re.findall(r\"\\[p(\\d+)_\", answer))\n",
    "    if not pages:\n",
    "        pages = set(int(p) for p in re.findall(r\"\\bp(\\d+)\\b\", answer))\n",
    "    return pages\n",
    "\n",
    "def allowed_asset_indices(pages: set, window: int = 1):\n",
    "    if not pages:\n",
    "        return [i for i,u in enumerate(all_units) if u.unit_type in (\"figure\",\"table\")]\n",
    "    allowed_pages = set()\n",
    "    for p in pages:\n",
    "        for dp in range(-window, window+1):\n",
    "            if p + dp >= 1:\n",
    "                allowed_pages.add(p + dp)\n",
    "    return [i for i,u in enumerate(all_units) if (u.unit_type in (\"figure\",\"table\") and u.page in allowed_pages)]\n",
    "\n",
    "def retrieve_assets_filtered(query: str, allowed_idxs, top_k: int = 6):\n",
    "    if not allowed_idxs:\n",
    "        return []\n",
    "    q = embed_query(query)\n",
    "    sub = emb_n[allowed_idxs].astype(np.float32)\n",
    "    sub_index = build_faiss_ip_index(sub)\n",
    "    scores, sub_idxs = faiss_search(sub_index, q, min(top_k, len(allowed_idxs)))\n",
    "    return [(all_units[allowed_idxs[int(si)]], float(scores[r])) for r, si in enumerate(sub_idxs)]\n",
    "\n",
    "def show_asset_hits(asset_hits, max_show: int = 4):\n",
    "    for u, s in asset_hits[:max_show]:\n",
    "        print(f\"{u.unit_id} ({u.unit_type}) page={u.page} score={s:.3f}\")\n",
    "        if u.unit_type == \"figure\" and u.raw_content_ref:\n",
    "            display(Image.open(u.raw_content_ref))\n",
    "        elif u.unit_type == \"table\" and u.raw_content_ref:\n",
    "            if u.meta and u.meta.get(\"crop_image_path\") and os.path.exists(u.meta[\"crop_image_path\"]):\n",
    "                display(Image.open(u.meta[\"crop_image_path\"]))\n",
    "            html = open(u.raw_content_ref, \"r\", encoding=\"utf-8\").read()\n",
    "            print(html[:800] + (\"...\" if len(html) > 800 else \"\"))\n",
    "\n",
    "QUERY = \"What are the indian strategies in education system\"\n",
    "hits = retrieve_units(QUERY, top_k=TOP_K_TEXT)\n",
    "answer = answer_with_citations(QUERY, hits)\n",
    "print(answer)\n",
    "\n",
    "pages = cited_pages_from_answer(answer)\n",
    "print(\"\\nCited pages:\", sorted(pages))\n",
    "\n",
    "allowed_idxs = allowed_asset_indices(pages, window=PAGE_WINDOW)\n",
    "asset_hits = retrieve_assets_filtered(QUERY, allowed_idxs, top_k=TOP_K_ASSETS)\n",
    "\n",
    "print(\"\\nTop figures/tables from cited pages (±window):\")\n",
    "show_asset_hits(asset_hits, max_show=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c607afab",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Replace the heading heuristic with parser-provided section hierarchy when available.\n",
    "- If your parser returns normalized boxes, cropping is straightforward; if it returns absolute polygons (Azure DI), ensure correct unit conversion.\n",
    "- For production: store assets in object storage (GCS/S3) and persist metadata + embeddings in a DB/vector store.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
